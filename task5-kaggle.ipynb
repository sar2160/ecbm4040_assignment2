{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM E4040 - Assignment 2- Task 5: Kaggle Open-ended Competition\n",
    "\n",
    "Kaggle is a platform for predictive modelling and analytics competitions in which companies and researchers post data and statisticians and data miners compete to produce the best models for predicting and describing the data.\n",
    "\n",
    "If you don't have a Kaggle account, feel free to join at [www.kaggle.com](https://www.kaggle.com). To let the TAs do the grading more conveniently, please use Lionmail to join Kaggle and use UNI as your username.\n",
    "\n",
    "Visit the website for this competition to join: \n",
    "[https://www.kaggle.com/t/8dd419892b1c49a3afb0cea385a7e677](https://www.kaggle.com/t/8dd419892b1c49a3afb0cea385a7e677)\n",
    "\n",
    "Details about this in-class competition is shown on the website above. Please read carefully.\n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span>\n",
    "1. Train a custom model for the bottle dataset classification problem. You are free to use any methods taught in the class or found by yourself on the Internet (ALWAYS provide reference to the source). General training methods include:\n",
    "    * Dropout\n",
    "    * Batch normalization\n",
    "    * Early stopping\n",
    "    * l1-norm & l2-norm penalization\n",
    "2. You'll be given the test set to generate your predictions (70% public + 30% private, but you don't know which ones are public/private). Achieve 70% accuracy on the public test set. The accuracy will be shown on the public leaderboard once you submit your prediction .csv file. \n",
    "3. (A) Report your results on the Kaggle, for comparison with other students' optimization results (you should do this several times). (C) Save your best model, using BitBucket, at the same time when you (B) submit the homework files into Courseworks. See instructions below. \n",
    "\n",
    "__Hint__: You can start from what you implemented in task 4. Another classic classification model named 'VGG16' can also be easily implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW Submission Details:\n",
    "There are three components to reporting the results of this task: \n",
    "\n",
    "**(A) Submission (possible several) of the .csv prediction file throught the Kaggle platform;**. You should start doing this VARY early, so that students can compare their work as they are making progress with model optimization.\n",
    "\n",
    "**(B) Editing and submitting the content of this Jupyter notebook, through Courseworks; **\n",
    "(i) The code for your CNN model and for the training function. The code should be stored in __./ecbm4040/neuralnets/kaggle.py__;\n",
    "(ii) Print out your training process and accuracy __within this notebook__;\n",
    "\n",
    "**(C) Submitting your best CNN model through instructor-owned private BitBucket repo.**\n",
    "\n",
    "**Description of (C):** \n",
    "For this task, you will be utilizing bitbucket to save your model for submission. Bitbucket provides Git code managment. For those who are not familiar with git operations, please check [Learn Git with Bitbucket Cloud](https://www.atlassian.com/git/tutorials/learn-git-with-bitbucket-cloud) as reference.\n",
    "**TAs will create a private Bitbucket repository for each student, with the write access. This repo will be owned by the instructors. Make sure to properly submit your model to that exact repository (submissions to your own private repository will not count)** Students need to populate the following file to provide instructors with bitbucket account information: https://docs.google.com/spreadsheets/d/1_7cZjyr34I2y-AD_0N5UaJ3ZnqdhYcvrdoTsYvOSd-g/edit#gid=0.\n",
    "\n",
    "<span style=\"color:red\">__Submission content:__ :</span>\n",
    "(i) Upload your best model with all the data output (for example, __MODEL.data-00000-of-00001, MODEL.meta, MODEL.index__) into the  BitBucket. Store your model in the folder named \"__KaggleModel__\" within the BitBucket repository. \n",
    "Remember to delete any intermediate results, **we only want your best model. Do not upload any data files**. The instructors will rerun the uploaded best model and verify against the score which you reported on the Kaggle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import modules\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 images in batch\n",
      "0\n",
      "3000 images in batch\n",
      "1\n",
      "3000 images in batch\n",
      "2\n",
      "3000 images in batch\n",
      "3\n",
      "3000 images in batch\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "paths = [ \"kaggle/train_128/0/*.png\" , \"kaggle/train_128/1/*.png\" ,\\\n",
    "         \"kaggle/train_128/2/*.png\" ,  \"kaggle/train_128/3/*.png\" , \\\n",
    "         \"kaggle/train_128/4/*.png\"]   \n",
    "\n",
    "\n",
    "X_train = np.empty((15000,64,64,3))\n",
    "y_train = np.empty(15000)\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    filenames = glob.glob(path)\n",
    "    temp = np.empty((len(filenames), 64, 64,3))\n",
    "    print(str(len(filenames)) + ' images in batch'  )\n",
    "    for j, fname in enumerate(filenames):\n",
    "        img = Image.open(fname)\n",
    "        img = img.resize((64,64),Image.NEAREST)\n",
    "        arr = np.array(img)\n",
    "        X_train[(3000*i) + j] = arr / 255\n",
    "        y_train[(3000*i) + j] = i\n",
    "    print(path[-7])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14200, 64, 64, 3) (800, 64, 64, 3) (100, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "num_train = 14200 \n",
    "num_val = 800\n",
    "num_dev = 100\n",
    "\n",
    "reshape = np.random.permutation(X_train.shape[0])\n",
    "\n",
    "X_train = X_train[reshape]\n",
    "y_train = y_train[reshape]\n",
    "\n",
    "# The development set is used for augmentation practices.\n",
    "mask = np.random.choice(num_train, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "\n",
    "# Seperate Training set into a training set and a validation set\n",
    "X_val = X_train[num_train:]\n",
    "y_val = y_train[num_train:]\n",
    "X_train = X_train[:num_train]\n",
    "y_train = y_train[:num_train]\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing: subtract the mean value across every dimension for training data, and reshape it to be RGB size\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train = X_train.astype(np.float32) - mean_image.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32) - mean_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecbm4040.image_generator import ImageGenerator\n",
    "\n",
    "dev_gen = ImageGenerator(X_dev , y_dev)\n",
    "dev_gen.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dev_gen\n",
    "\n",
    "\n",
    "Train_X_Gen = ImageGenerator(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[10]\n",
      "fc_units=[84, 84]\n",
      "conv_kernel_size=[5]\n",
      "pooling_size=[2]\n",
      "l2_norm=0.0001\n",
      "seed=235\n",
      "learning_rate=0.001\n",
      "number of batches for training: 57\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 69.75%\n",
      "epoch 3 \n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:200 accuracy: 76.375%\n",
      "epoch 5 \n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:300 accuracy: 79.875%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:400 accuracy: 83.625%\n",
      "epoch 9 \n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:1100 accuracy: 84.125%\n",
      "Traning ends. The best valid accuracy is 84.125. Model named lenet_1509848889.\n"
     ]
    }
   ],
   "source": [
    "from ecbm4040.neuralnets.cnn_kaggle import my_training\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "result , cache = my_training(X_train, y_train, X_val, y_val, \n",
    "             conv_featmap=[10],\n",
    "             fc_units=[84, 84],\n",
    "             conv_kernel_size=[5],\n",
    "             pooling_size=[2],\n",
    "             l2_norm= .0001,\n",
    "             seed=235,\n",
    "             use_adam = True,\n",
    "             learning_rate= .001,\n",
    "             epoch=20,\n",
    "             batch_size=245,\n",
    "             verbose=False,\n",
    "             pre_trained_model= None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: \n",
      "\n",
      "kernel size: 5\n",
      "\n",
      "penalty: 1e-05\n",
      "\n",
      "learning rate: 0.1\n",
      "\n",
      "batch size: 75\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[10]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[5]\n",
      "pooling_size=[2]\n",
      "l2_norm=0.1\n",
      "seed=235\n",
      "learning_rate=1e-05\n",
      "number of batches for training: 189\n",
      "epoch 1 \n",
      "Best validation accuracy! iteration:100 accuracy: 35.625%\n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:200 accuracy: 44.625%\n",
      "Best validation accuracy! iteration:300 accuracy: 48.875%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:400 accuracy: 53.75%\n",
      "Best validation accuracy! iteration:500 accuracy: 56.125%\n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:600 accuracy: 56.875%\n",
      "Best validation accuracy! iteration:700 accuracy: 57.625%\n",
      "epoch 5 \n",
      "Best validation accuracy! iteration:800 accuracy: 59.25%\n",
      "Best validation accuracy! iteration:900 accuracy: 59.625%\n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:1000 accuracy: 60.875%\n",
      "epoch 7 \n",
      "Best validation accuracy! iteration:1200 accuracy: 61.375%\n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:1500 accuracy: 62.75%\n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:1700 accuracy: 63.625%\n",
      "epoch 10 \n",
      "Best validation accuracy! iteration:1800 accuracy: 64.375%\n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:2000 accuracy: 65.625%\n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "Best validation accuracy! iteration:2500 accuracy: 66.25%\n",
      "Best validation accuracy! iteration:2600 accuracy: 66.75%\n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:2800 accuracy: 67.0%\n",
      "epoch 16 \n",
      "Best validation accuracy! iteration:3000 accuracy: 67.125%\n",
      "epoch 17 \n",
      "epoch 18 \n",
      "Best validation accuracy! iteration:3300 accuracy: 67.5%\n",
      "Best validation accuracy! iteration:3400 accuracy: 68.125%\n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:3700 accuracy: 68.75%\n",
      "Traning ends. The best valid accuracy is 68.75. Model named lenet_1509843647.\n",
      "iteration 1: \n",
      "\n",
      "kernel size: 2\n",
      "\n",
      "penalty: 1e-05\n",
      "\n",
      "learning rate: 0.1\n",
      "\n",
      "batch size: 150\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[3]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[2]\n",
      "pooling_size=[10]\n",
      "l2_norm=0.1\n",
      "seed=235\n",
      "learning_rate=1e-05\n",
      "number of batches for training: 94\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 1.75%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:200 accuracy: 4.875%\n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:300 accuracy: 8.125%\n",
      "epoch 5 \n",
      "Best validation accuracy! iteration:400 accuracy: 11.375%\n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:500 accuracy: 14.875%\n",
      "epoch 7 \n",
      "Best validation accuracy! iteration:600 accuracy: 16.625%\n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:700 accuracy: 17.625%\n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:800 accuracy: 17.75%\n",
      "epoch 10 \n",
      "Best validation accuracy! iteration:900 accuracy: 18.0%\n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:1000 accuracy: 18.125%\n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:1400 accuracy: 18.25%\n",
      "epoch 16 \n",
      "Best validation accuracy! iteration:1500 accuracy: 18.375%\n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 18.375. Model named lenet_1509843707.\n",
      "iteration 2: \n",
      "\n",
      "kernel size: 10\n",
      "\n",
      "penalty: 0.001\n",
      "\n",
      "learning rate: 0.0001\n",
      "\n",
      "batch size: 75\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[6]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[10]\n",
      "pooling_size=[7]\n",
      "l2_norm=0.0001\n",
      "seed=235\n",
      "learning_rate=0.001\n",
      "number of batches for training: 189\n",
      "epoch 1 \n",
      "Best validation accuracy! iteration:100 accuracy: 60.0%\n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:200 accuracy: 67.125%\n",
      "Best validation accuracy! iteration:300 accuracy: 72.125%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:400 accuracy: 72.875%\n",
      "Best validation accuracy! iteration:500 accuracy: 73.75%\n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:600 accuracy: 77.875%\n",
      "epoch 5 \n",
      "Best validation accuracy! iteration:800 accuracy: 78.75%\n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:1100 accuracy: 80.375%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:1400 accuracy: 81.875%\n",
      "epoch 9 \n",
      "epoch 10 \n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:1900 accuracy: 83.0%\n",
      "epoch 12 \n",
      "Best validation accuracy! iteration:2100 accuracy: 83.125%\n",
      "epoch 13 \n",
      "Best validation accuracy! iteration:2300 accuracy: 83.875%\n",
      "epoch 14 \n",
      "epoch 15 \n",
      "epoch 16 \n",
      "epoch 17 \n",
      "Best validation accuracy! iteration:3100 accuracy: 84.0%\n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 84.0. Model named lenet_1509843731.\n",
      "iteration 3: \n",
      "\n",
      "kernel size: 2\n",
      "\n",
      "penalty: 0.01\n",
      "\n",
      "learning rate: 0.1\n",
      "\n",
      "batch size: 150\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[6]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[2]\n",
      "pooling_size=[10]\n",
      "l2_norm=0.1\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "number of batches for training: 94\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 29.75%\n",
      "epoch 3 \n",
      "epoch 4 \n",
      "epoch 5 \n",
      "epoch 6 \n",
      "epoch 7 \n",
      "epoch 8 \n",
      "epoch 9 \n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 29.75. Model named lenet_1509843780.\n",
      "iteration 4: \n",
      "\n",
      "kernel size: 5\n",
      "\n",
      "penalty: 0.01\n",
      "\n",
      "learning rate: 0.1\n",
      "\n",
      "batch size: 250\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[3]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[5]\n",
      "pooling_size=[2]\n",
      "l2_norm=0.1\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "number of batches for training: 56\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 52.0%\n",
      "epoch 3 \n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:200 accuracy: 65.0%\n",
      "epoch 5 \n",
      "epoch 6 \n",
      "epoch 7 \n",
      "epoch 8 \n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:500 accuracy: 66.0%\n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:1100 accuracy: 68.375%\n",
      "Traning ends. The best valid accuracy is 68.375. Model named lenet_1509843808.\n",
      "iteration 5: \n",
      "\n",
      "kernel size: 10\n",
      "\n",
      "penalty: 1e-05\n",
      "\n",
      "learning rate: 0.1\n",
      "\n",
      "batch size: 150\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[10]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[10]\n",
      "pooling_size=[7]\n",
      "l2_norm=0.1\n",
      "seed=235\n",
      "learning_rate=1e-05\n",
      "number of batches for training: 94\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 18.125%\n",
      "epoch 3 \n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:300 accuracy: 19.625%\n",
      "epoch 5 \n",
      "Best validation accuracy! iteration:400 accuracy: 23.625%\n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:500 accuracy: 28.125%\n",
      "epoch 7 \n",
      "Best validation accuracy! iteration:600 accuracy: 34.125%\n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:700 accuracy: 38.0%\n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:800 accuracy: 39.25%\n",
      "epoch 10 \n",
      "Best validation accuracy! iteration:900 accuracy: 41.75%\n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:1000 accuracy: 43.5%\n",
      "epoch 12 \n",
      "Best validation accuracy! iteration:1100 accuracy: 44.25%\n",
      "epoch 13 \n",
      "Best validation accuracy! iteration:1200 accuracy: 45.875%\n",
      "epoch 14 \n",
      "Best validation accuracy! iteration:1300 accuracy: 47.25%\n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:1400 accuracy: 48.125%\n",
      "epoch 16 \n",
      "Best validation accuracy! iteration:1500 accuracy: 48.625%\n",
      "epoch 17 \n",
      "epoch 18 \n",
      "Best validation accuracy! iteration:1600 accuracy: 49.375%\n",
      "epoch 19 \n",
      "Best validation accuracy! iteration:1700 accuracy: 49.75%\n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:1800 accuracy: 50.25%\n",
      "Traning ends. The best valid accuracy is 50.25. Model named lenet_1509843835.\n",
      "iteration 6: \n",
      "\n",
      "kernel size: 10\n",
      "\n",
      "penalty: 0.01\n",
      "\n",
      "learning rate: 0.0001\n",
      "\n",
      "batch size: 400\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[10]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[10]\n",
      "pooling_size=[7]\n",
      "l2_norm=0.0001\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "number of batches for training: 35\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:100 accuracy: 73.0%\n",
      "epoch 4 \n",
      "epoch 5 \n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:200 accuracy: 79.75%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:300 accuracy: 82.625%\n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:500 accuracy: 83.625%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "Best validation accuracy! iteration:600 accuracy: 84.25%\n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 84.25. Model named lenet_1509843887.\n",
      "iteration 7: \n",
      "\n",
      "kernel size: 2\n",
      "\n",
      "penalty: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "batch size: 75\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[3]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[2]\n",
      "pooling_size=[5]\n",
      "l2_norm=0.01\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "number of batches for training: 189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 \n",
      "Best validation accuracy! iteration:100 accuracy: 61.375%\n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:200 accuracy: 70.25%\n",
      "epoch 3 \n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:600 accuracy: 71.625%\n",
      "Best validation accuracy! iteration:700 accuracy: 73.75%\n",
      "epoch 5 \n",
      "epoch 6 \n",
      "epoch 7 \n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:1500 accuracy: 76.375%\n",
      "epoch 9 \n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 76.375. Model named lenet_1509843932.\n",
      "iteration 8: \n",
      "\n",
      "kernel size: 2\n",
      "\n",
      "penalty: 0.001\n",
      "\n",
      "learning rate: 0.0001\n",
      "\n",
      "batch size: 400\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[10]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[2]\n",
      "pooling_size=[10]\n",
      "l2_norm=0.0001\n",
      "seed=235\n",
      "learning_rate=0.001\n",
      "number of batches for training: 35\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:100 accuracy: 59.125%\n",
      "epoch 4 \n",
      "epoch 5 \n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:200 accuracy: 65.625%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:300 accuracy: 68.875%\n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "Best validation accuracy! iteration:400 accuracy: 71.125%\n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:500 accuracy: 71.5%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "Best validation accuracy! iteration:600 accuracy: 72.5%\n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 72.5. Model named lenet_1509843962.\n",
      "iteration 9: \n",
      "\n",
      "kernel size: 2\n",
      "\n",
      "penalty: 0.001\n",
      "\n",
      "learning rate: 0.1\n",
      "\n",
      "batch size: 75\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[3]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[2]\n",
      "pooling_size=[10]\n",
      "l2_norm=0.1\n",
      "seed=235\n",
      "learning_rate=0.001\n",
      "number of batches for training: 189\n",
      "epoch 1 \n",
      "Best validation accuracy! iteration:100 accuracy: 37.125%\n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:200 accuracy: 47.125%\n",
      "Best validation accuracy! iteration:300 accuracy: 48.75%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:400 accuracy: 50.75%\n",
      "epoch 4 \n",
      "epoch 5 \n",
      "epoch 6 \n",
      "epoch 7 \n",
      "Best validation accuracy! iteration:1300 accuracy: 51.625%\n",
      "epoch 8 \n",
      "epoch 9 \n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 51.625. Model named lenet_1509843990.\n",
      "iteration 10: \n",
      "\n",
      "kernel size: 2\n",
      "\n",
      "penalty: 0.01\n",
      "\n",
      "learning rate: 0.0001\n",
      "\n",
      "batch size: 250\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[3]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[2]\n",
      "pooling_size=[10]\n",
      "l2_norm=0.0001\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "number of batches for training: 56\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 53.625%\n",
      "epoch 3 \n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:200 accuracy: 58.0%\n",
      "epoch 5 \n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:300 accuracy: 59.375%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:400 accuracy: 61.75%\n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:500 accuracy: 62.125%\n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "epoch 13 \n",
      "Best validation accuracy! iteration:700 accuracy: 64.0%\n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:800 accuracy: 67.0%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:1100 accuracy: 69.625%\n",
      "Traning ends. The best valid accuracy is 69.625. Model named lenet_1509844020.\n",
      "iteration 11: \n",
      "\n",
      "kernel size: 10\n",
      "\n",
      "penalty: 0.01\n",
      "\n",
      "learning rate: 0.0001\n",
      "\n",
      "batch size: 250\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[3]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[10]\n",
      "pooling_size=[1]\n",
      "l2_norm=0.0001\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "number of batches for training: 56\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 53.25%\n",
      "epoch 3 \n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:200 accuracy: 60.25%\n",
      "epoch 5 \n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:300 accuracy: 62.125%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:400 accuracy: 67.25%\n",
      "epoch 9 \n",
      "epoch 10 \n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:600 accuracy: 68.875%\n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:800 accuracy: 69.375%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:1100 accuracy: 71.25%\n",
      "Traning ends. The best valid accuracy is 71.25. Model named lenet_1509844042.\n",
      "iteration 12: \n",
      "\n",
      "kernel size: 5\n",
      "\n",
      "penalty: 0.0001\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "batch size: 150\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[10]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[5]\n",
      "pooling_size=[1]\n",
      "l2_norm=0.01\n",
      "seed=235\n",
      "learning_rate=0.0001\n",
      "number of batches for training: 94\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 61.75%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:200 accuracy: 65.875%\n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:300 accuracy: 68.25%\n",
      "epoch 5 \n",
      "Best validation accuracy! iteration:400 accuracy: 69.125%\n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:500 accuracy: 69.25%\n",
      "epoch 7 \n",
      "Best validation accuracy! iteration:600 accuracy: 71.0%\n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:700 accuracy: 73.0%\n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:800 accuracy: 73.625%\n",
      "epoch 10 \n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:1000 accuracy: 74.25%\n",
      "epoch 12 \n",
      "epoch 13 \n",
      "Best validation accuracy! iteration:1200 accuracy: 75.125%\n",
      "epoch 14 \n",
      "Best validation accuracy! iteration:1300 accuracy: 76.25%\n",
      "epoch 15 \n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "Best validation accuracy! iteration:1600 accuracy: 76.625%\n",
      "epoch 19 \n",
      "Best validation accuracy! iteration:1700 accuracy: 77.25%\n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:1800 accuracy: 78.875%\n",
      "Traning ends. The best valid accuracy is 78.875. Model named lenet_1509844077.\n",
      "iteration 13: \n",
      "\n",
      "kernel size: 10\n",
      "\n",
      "penalty: 0.0001\n",
      "\n",
      "learning rate: 0.1\n",
      "\n",
      "batch size: 400\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[6]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[10]\n",
      "pooling_size=[7]\n",
      "l2_norm=0.1\n",
      "seed=235\n",
      "learning_rate=0.0001\n",
      "number of batches for training: 35\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:100 accuracy: 28.125%\n",
      "epoch 4 \n",
      "epoch 5 \n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:200 accuracy: 38.5%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:300 accuracy: 46.125%\n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "Best validation accuracy! iteration:400 accuracy: 50.0%\n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:500 accuracy: 52.875%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "Best validation accuracy! iteration:600 accuracy: 54.0%\n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 54.0. Model named lenet_1509844151.\n",
      "iteration 14: \n",
      "\n",
      "kernel size: 5\n",
      "\n",
      "penalty: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "batch size: 150\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[3]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[5]\n",
      "pooling_size=[5]\n",
      "l2_norm=0.01\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "number of batches for training: 94\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 70.625%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:200 accuracy: 75.125%\n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:300 accuracy: 78.5%\n",
      "epoch 5 \n",
      "epoch 6 \n",
      "epoch 7 \n",
      "Best validation accuracy! iteration:600 accuracy: 79.0%\n",
      "epoch 8 \n",
      "epoch 9 \n",
      "epoch 10 \n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:1000 accuracy: 79.5%\n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 79.5. Model named lenet_1509844186.\n",
      "iteration 15: \n",
      "\n",
      "kernel size: 2\n",
      "\n",
      "penalty: 0.001\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "batch size: 250\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[3]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[2]\n",
      "pooling_size=[2]\n",
      "l2_norm=0.01\n",
      "seed=235\n",
      "learning_rate=0.001\n",
      "number of batches for training: 56\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 65.375%\n",
      "epoch 3 \n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:200 accuracy: 69.5%\n",
      "epoch 5 \n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:300 accuracy: 69.75%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:400 accuracy: 74.25%\n",
      "epoch 9 \n",
      "epoch 10 \n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:600 accuracy: 74.375%\n",
      "epoch 12 \n",
      "epoch 13 \n",
      "Best validation accuracy! iteration:700 accuracy: 76.75%\n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:800 accuracy: 76.875%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "Best validation accuracy! iteration:900 accuracy: 77.375%\n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 77.375. Model named lenet_1509844215.\n",
      "iteration 16: \n",
      "\n",
      "kernel size: 10\n",
      "\n",
      "penalty: 1e-05\n",
      "\n",
      "learning rate: 0.1\n",
      "\n",
      "batch size: 150\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[3]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[10]\n",
      "pooling_size=[10]\n",
      "l2_norm=0.1\n",
      "seed=235\n",
      "learning_rate=1e-05\n",
      "number of batches for training: 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 13.375%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:200 accuracy: 16.125%\n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:300 accuracy: 17.25%\n",
      "epoch 5 \n",
      "Best validation accuracy! iteration:400 accuracy: 17.625%\n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:500 accuracy: 18.25%\n",
      "epoch 7 \n",
      "Best validation accuracy! iteration:600 accuracy: 19.0%\n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:700 accuracy: 19.75%\n",
      "epoch 9 \n",
      "epoch 10 \n",
      "Best validation accuracy! iteration:900 accuracy: 20.25%\n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:1000 accuracy: 20.875%\n",
      "epoch 12 \n",
      "Best validation accuracy! iteration:1100 accuracy: 22.25%\n",
      "epoch 13 \n",
      "Best validation accuracy! iteration:1200 accuracy: 23.625%\n",
      "epoch 14 \n",
      "Best validation accuracy! iteration:1300 accuracy: 25.0%\n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:1400 accuracy: 25.875%\n",
      "epoch 16 \n",
      "Best validation accuracy! iteration:1500 accuracy: 27.75%\n",
      "epoch 17 \n",
      "epoch 18 \n",
      "Best validation accuracy! iteration:1600 accuracy: 29.125%\n",
      "epoch 19 \n",
      "Best validation accuracy! iteration:1700 accuracy: 29.5%\n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:1800 accuracy: 30.875%\n",
      "Traning ends. The best valid accuracy is 30.875. Model named lenet_1509844238.\n",
      "iteration 17: \n",
      "\n",
      "kernel size: 10\n",
      "\n",
      "penalty: 0.01\n",
      "\n",
      "learning rate: 0.1\n",
      "\n",
      "batch size: 250\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[6]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[10]\n",
      "pooling_size=[2]\n",
      "l2_norm=0.1\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "number of batches for training: 56\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 61.75%\n",
      "epoch 3 \n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:200 accuracy: 62.25%\n",
      "epoch 5 \n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:300 accuracy: 64.875%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:400 accuracy: 65.875%\n",
      "epoch 9 \n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:800 accuracy: 68.375%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 68.375. Model named lenet_1509844271.\n",
      "iteration 18: \n",
      "\n",
      "kernel size: 2\n",
      "\n",
      "penalty: 0.0001\n",
      "\n",
      "learning rate: 0.0001\n",
      "\n",
      "batch size: 75\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[6]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[2]\n",
      "pooling_size=[10]\n",
      "l2_norm=0.0001\n",
      "seed=235\n",
      "learning_rate=0.0001\n",
      "number of batches for training: 189\n",
      "epoch 1 \n",
      "Best validation accuracy! iteration:100 accuracy: 22.25%\n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:200 accuracy: 28.375%\n",
      "Best validation accuracy! iteration:300 accuracy: 34.625%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:400 accuracy: 40.5%\n",
      "Best validation accuracy! iteration:500 accuracy: 42.875%\n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:600 accuracy: 47.375%\n",
      "Best validation accuracy! iteration:700 accuracy: 48.5%\n",
      "epoch 5 \n",
      "Best validation accuracy! iteration:800 accuracy: 52.75%\n",
      "Best validation accuracy! iteration:900 accuracy: 53.625%\n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:1000 accuracy: 54.875%\n",
      "Best validation accuracy! iteration:1100 accuracy: 57.0%\n",
      "epoch 7 \n",
      "Best validation accuracy! iteration:1200 accuracy: 57.125%\n",
      "Best validation accuracy! iteration:1300 accuracy: 57.5%\n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:1400 accuracy: 58.625%\n",
      "Best validation accuracy! iteration:1500 accuracy: 59.375%\n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:1600 accuracy: 60.625%\n",
      "Best validation accuracy! iteration:1700 accuracy: 61.0%\n",
      "epoch 10 \n",
      "Best validation accuracy! iteration:1800 accuracy: 61.5%\n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:1900 accuracy: 61.75%\n",
      "Best validation accuracy! iteration:2000 accuracy: 63.125%\n",
      "epoch 12 \n",
      "Best validation accuracy! iteration:2200 accuracy: 63.25%\n",
      "epoch 13 \n",
      "Best validation accuracy! iteration:2300 accuracy: 64.25%\n",
      "Best validation accuracy! iteration:2400 accuracy: 65.125%\n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:2800 accuracy: 65.5%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "Best validation accuracy! iteration:3200 accuracy: 66.25%\n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:3600 accuracy: 66.75%\n",
      "Traning ends. The best valid accuracy is 66.75. Model named lenet_1509844310.\n",
      "iteration 19: \n",
      "\n",
      "kernel size: 10\n",
      "\n",
      "penalty: 1e-05\n",
      "\n",
      "learning rate: 0.0001\n",
      "\n",
      "batch size: 400\n",
      "\n",
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[3]\n",
      "fc_units=[128, 84]\n",
      "conv_kernel_size=[10]\n",
      "pooling_size=[7]\n",
      "l2_norm=0.0001\n",
      "seed=235\n",
      "learning_rate=1e-05\n",
      "number of batches for training: 35\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:100 accuracy: 15.75%\n",
      "epoch 4 \n",
      "epoch 5 \n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:200 accuracy: 19.0%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:300 accuracy: 19.25%\n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "Best validation accuracy! iteration:400 accuracy: 19.875%\n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:500 accuracy: 21.375%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "Best validation accuracy! iteration:600 accuracy: 23.125%\n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:700 accuracy: 26.625%\n",
      "Traning ends. The best valid accuracy is 26.625. Model named lenet_1509844345.\n"
     ]
    }
   ],
   "source": [
    "from ecbm4040.neuralnets.cnn_kaggle import my_training\n",
    "import tensorflow as tf\n",
    "\n",
    "kernel_sizes = [2, 5 ,10]\n",
    "l2_penalties = [.00001, .0001 , .001, .01]\n",
    "learning_rates = [1e-4, 1e-2, 1e-1]\n",
    "batch_sizes    = [75, 150, 250, 400]\n",
    "pooling_size   = [1, 2, 5, 7, 10]\n",
    "conv_features  = [ 3, 6, 10 ]\n",
    "\n",
    "results = list()\n",
    "parameters = list()\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    k = np.random.choice(kernel_sizes)\n",
    "    l = np.random.choice(l2_penalties)\n",
    "    r = np.random.choice(learning_rates)\n",
    "    b = np.random.choice(batch_sizes)\n",
    "    p = np.random.choice(pooling_size)\n",
    "    f = np.random.choice(conv_features)\n",
    "\n",
    "    print('iteration ' + str(i) + ': \\n')\n",
    "    print('kernel size: ' + str(k)+ '\\n')\n",
    "    print('penalty: ' + str(l)+ '\\n')\n",
    "    print('learning rate: ' + str(r)+ '\\n')\n",
    "    print('batch size: ' + str(b)+ '\\n')\n",
    "\n",
    "\n",
    "    result , cache = my_training(X_train, y_train, X_val, y_val, \n",
    "             conv_featmap=[f],\n",
    "             fc_units=[128, 84],\n",
    "             conv_kernel_size=[k],\n",
    "             pooling_size=[p],\n",
    "             l2_norm= r,\n",
    "             seed=235,\n",
    "             use_adam = True,\n",
    "             learning_rate= l,\n",
    "             epoch=20,\n",
    "             batch_size=b,\n",
    "             verbose=False,\n",
    "             pre_trained_model=None)\n",
    "    \n",
    "    results.append(result)\n",
    "    parameters.append(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[68.75,\n",
       " 18.375,\n",
       " 84.0,\n",
       " 29.75,\n",
       " 68.375,\n",
       " 50.25,\n",
       " 84.25,\n",
       " 76.375,\n",
       " 72.5,\n",
       " 51.625,\n",
       " 69.625,\n",
       " 71.25,\n",
       " 78.875,\n",
       " 54.0,\n",
       " 79.5,\n",
       " 77.375,\n",
       " 30.875,\n",
       " 68.375,\n",
       " 66.75,\n",
       " 26.625]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/lenet_1509848889\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [128] rhs shape= [84]\n\t [[Node: save/Assign_8 = Assign[T=DT_FLOAT, _class=[\"loc:@fc_layer_0/fc_kernel/fc_bias_0\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](fc_layer_0/fc_kernel/fc_bias_0/Adam_1, save/RestoreV2_8/_9)]]\n\nCaused by op 'save/Assign_8', defined at:\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-61-10747f79722a>\", line 6, in <module>\n    saver = tf.train.import_meta_graph('model/lenet_1509844345.meta')\n  File \"/home/ecbm4040/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1698, in import_meta_graph\n    **kwargs)\n  File \"/home/ecbm4040/.local/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\", line 656, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/home/ecbm4040/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\n    op_def=op_def)\n  File \"/home/ecbm4040/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ecbm4040/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [128] rhs shape= [84]\n\t [[Node: save/Assign_8 = Assign[T=DT_FLOAT, _class=[\"loc:@fc_layer_0/fc_kernel/fc_bias_0\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](fc_layer_0/fc_kernel/fc_bias_0/Adam_1, save/RestoreV2_8/_9)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/dlenv/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [128] rhs shape= [84]\n\t [[Node: save/Assign_8 = Assign[T=DT_FLOAT, _class=[\"loc:@fc_layer_0/fc_kernel/fc_bias_0\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](fc_layer_0/fc_kernel/fc_bias_0/Adam_1, save/RestoreV2_8/_9)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-10747f79722a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/lenet_1509844345.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1560\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [128] rhs shape= [84]\n\t [[Node: save/Assign_8 = Assign[T=DT_FLOAT, _class=[\"loc:@fc_layer_0/fc_kernel/fc_bias_0\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](fc_layer_0/fc_kernel/fc_bias_0/Adam_1, save/RestoreV2_8/_9)]]\n\nCaused by op 'save/Assign_8', defined at:\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-61-10747f79722a>\", line 6, in <module>\n    saver = tf.train.import_meta_graph('model/lenet_1509844345.meta')\n  File \"/home/ecbm4040/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1698, in import_meta_graph\n    **kwargs)\n  File \"/home/ecbm4040/.local/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\", line 656, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/home/ecbm4040/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\n    op_def=op_def)\n  File \"/home/ecbm4040/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ecbm4040/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [128] rhs shape= [84]\n\t [[Node: save/Assign_8 = Assign[T=DT_FLOAT, _class=[\"loc:@fc_layer_0/fc_kernel/fc_bias_0\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](fc_layer_0/fc_kernel/fc_bias_0/Adam_1, save/RestoreV2_8/_9)]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "from ecbm4040.neuralnets.cnn_kaggle import evaluate\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('model/lenet_1509844345.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('model/'))\n",
    "    ys = tf.placeholder(shape=[None, ], dtype=tf.int64)\n",
    "\n",
    "    \n",
    "    eve = evaluate(saver, ys)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    valid_eve = sess.run([eve], feed_dict={xs: X_val, ys: y_val})\n",
    "    valid_acc = 100 - valid_eve * 100 / y_val.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "latest_checkpoint() missing 1 required positional argument: 'checkpoint_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-d757113e2277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/lenet_1509844345.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: latest_checkpoint() missing 1 required positional argument: 'checkpoint_dir'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    saver = tf.train.import_meta_graph('model/lenet_1509844345.meta')\n",
    "    saver.restore(session, tf.train.latest_checkpoint())\n",
    "\n",
    "    feed_dict = {tf_train_dataset : batch_data}\n",
    "    predictions = session.run([test_prediction], feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate .csv file for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following code snippet can be used to generate your prediction .csv file.\n",
    "\n",
    "# import csv\n",
    "# with open('predicted.csv','w') as csvfile:\n",
    "#     fieldnames = ['Id','label']\n",
    "#     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "#     writer.writeheader()    \n",
    "#     for index,l in enumerate(predicted_values_generated_by_your_model):\n",
    "#         filename = str(index)+'.png'\n",
    "#         label = str(l)\n",
    "#         writer.writerow({'Id': filename, 'label': label})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
